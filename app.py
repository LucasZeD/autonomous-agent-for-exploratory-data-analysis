# /ui/app.py
import sys
import os
import streamlit as st
import pandas as pd
import base64
import re
from llm.llm_factory import LLMFactory
from graph.eda_graph import create_eda_graph
from tools.rag_tool import setup_vectorstore
from langchain_core.messages import AIMessage, HumanMessage

st.set_page_config(page_title="Agente de An치lise de CSV", layout="wide")

st.title("游뱄 Agente Metodol칩gico para An치lise de Dados (E.D.A.)")
st.markdown("Desenvolvido com `LangGraph` para an치lises de alta acur치cia.")

# --- Inicializa칞칚o do Estado da Sess칚o ---
def init_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "graph_runner" not in st.session_state:
        st.session_state.graph_runner = None

init_session_state()

# --- BARRA LATERAL (CONFIGURA칂칏ES) ---
with st.sidebar:
    st.header("Configura칞칫es")
    
    uploaded_csv = st.file_uploader("1. Carregue seu arquivo CSV", type="csv")
    
    uploaded_pdfs = st.file_uploader(
        "2. (Opcional) Carregue PDFs para a Base de Conhecimento (RAG)",
        type="pdf",
        accept_multiple_files=True
    )
    
    llm_provider = st.selectbox("3. Escolha o provedor de LLM", ("Gemini", "GPT", "LocalLM"))
    
    api_key = None
    if llm_provider in ["GPT", "Gemini"]:
        api_key = st.text_input(f"Insira a chave de API do {llm_provider}", type="password")

    if st.button("游 Iniciar Agente"):
        if uploaded_csv is not None:
            with st.spinner("Processando arquivos e construindo o grafo..."):
                try:
                    df = pd.read_csv(uploaded_csv)
                    
                    if uploaded_pdfs:
                        setup_vectorstore(uploaded_pdfs)
                        st.success("Base de conhecimento (RAG) criada com sucesso!")
                    
                    llm = LLMFactory.create_llm(llm_provider, api_key)
                    st.session_state.graph_runner = create_eda_graph(llm, df)
                    
                    st.session_state.messages = []
                    st.success(f"Agente inicializado com {llm_provider}. Pronto para an치lise!")
                except Exception as e:
                    st.error(f"Erro na inicializa칞칚o: {e}")
        else:
            st.warning("Por favor, carregue um arquivo CSV para come칞ar.")

# --- 츼REA PRINCIPAL DO CHAT ---
def display_chat_history():
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "image" in msg:
                st.image(base64.b64decode(msg["image"]))

if st.session_state.graph_runner:
    st.info(f"Agente pronto! Fa칞a perguntas sobre o arquivo `{uploaded_csv.name}`.")
    display_chat_history()
    
    if prompt := st.chat_input("Ex: 'Qual a correla칞칚o entre as colunas V1 e Amount?'"):
        st.session_state.messages.append({"role": "user", "content": prompt, "lc_message": HumanMessage(content=prompt)})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("O agente est치 executando o workflow de an치lise..."):
                chat_history = [msg["lc_message"] for msg in st.session_state.messages[:-1]]

                final_state = st.session_state.graph_runner(prompt, chat_history)
                                
                conclusion = final_state.get("conclusion", "N칚o foi poss칤vel gerar uma conclus칚o.")
                
                result_text = str(final_state.get("execution_result", ""))
                
                plot_match = re.search(r'\[PLOT_DATA:(.*?)\]', result_text)

                # added 1001250314
                assistant_message = {"role": "assistant", "content": conclusion, "lc_message": AIMessage(content=conclusion)}
                
                if plot_match:
                    img_data = plot_match.group(1)
                    st.markdown(conclusion)
                    st.image(base64.b64decode(img_data))
                    assistant_message["image"] = img_data
                else:
                    st.markdown(conclusion)
                
                st.session_state.messages.append(assistant_message)
else:
    st.info("Por favor, configure o agente na barra lateral para come칞ar a an치lise.")